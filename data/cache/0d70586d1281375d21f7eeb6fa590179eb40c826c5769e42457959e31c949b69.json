{
  "model": "claude-haiku-4-5",
  "system_prompt_hash": "7c1ee11d93629999",
  "user_message_hash": "5054efc6b00c5b76",
  "max_tokens": 2048,
  "response": "## What ASR Measures in HarmBench\n\nAttack Success Rate (ASR) in HarmBench measures **the percentage of test cases that successfully elicit a target harmful behavior from an LLM** [harmbench, harmbench_c06]. More formally, ASR quantifies a red teaming method's success by evaluating how many of the designed test cases {x\u2081, x\u2082, ..., x\u2099} actually produce the desired harmful behavior y from the target model [harmbench, harmbench_c06].\n\n## Known Limitations\n\nThe context reveals several important limitations of ASR as implemented in HarmBench:\n\n**1. Copyright Behavior Measurement:** ASR is considerably lower for copyright behaviors because HarmBench uses \"a stricter standard than our non-copyright classifiers, requiring that completions actually contain the copyrighted text to be labeled positive\" [harmbench, harmbench_c18]. This means copyright ASR reflects a different evaluation criterion than other behavior categories.\n\n**2. Contextual Behaviors Show Inflated Success Rates:** ASR is \"considerably higher for contextual behaviors\" compared to standard behaviors [harmbench, harmbench_c18]. The researchers note this is concerning because \"contextual behaviors represent more specific harmful tasks that would be challenging to look up the answer to on a search engine\" [harmbench, harmbench_c47]. This suggests ASR may overstate the practical risk for these particular behavior types.\n\n**3. Model-Dependent Variability:** While ASR is averaged across models and attacks in aggregate reporting, \"there are substantial differences across models\" in semantic category performance [harmbench, harmbench_c18], indicating that a single ASR figure may mask important model-specific vulnerabilities.\n\nThe context does not provide additional methodological limitations of ASR itself as a metric.",
  "timestamp": "2026-03-01T19:48:02.025861+00:00"
}