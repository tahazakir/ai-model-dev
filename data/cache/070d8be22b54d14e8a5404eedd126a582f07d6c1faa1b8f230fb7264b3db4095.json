{
  "model": "claude-sonnet-4-6",
  "system_prompt_hash": "e86b58f46f5b8953",
  "user_message_hash": "259a687c6cf72066",
  "max_tokens": 4096,
  "response": "# Evidence Table: Multi-Turn Jailbreak Attack Strategies and Defenses\n\n| Claim | Evidence | Citation | Confidence | Notes |\n|---|---|---|---|---|\n| Multi-turn jailbreaks exploit dialogue dynamics by decomposing harmful queries into innocuous sub-questions | \"A common approach decomposes harmful queries into a series of innocuous sub-questions, progressively leading the model towards unsafe responses.\" | [fitd, fitd_c05] | HIGH | Describes a general category of multi-turn attacks; specific technique effectiveness varies by implementation |\n| The FITD attack achieves a 94% average attack success rate across seven widely used models | \"A simple yet effective two-stage method that outperforms existing state-of-the-art approaches in two jailbreak benchmarks, achieving an average success rate of 94% on seven widely used models.\" | [fitd, fitd_c04] | HIGH | Self-reported by the FITD authors; independent replication not confirmed in provided chunks |\n| Existing multi-turn attacks such as Crescendo and ActorAttack are constrained by fixed, human-crafted seed prompts and limited overall ASR | \"Multiturn attack Crescendo and ActorAttack incrementally steer seemingly benign queries toward harmful content but are constrained by their reliance on fixed, human-crafted seed prompts and limited overall ASR.\" | [fitd, fitd_c05] | HIGH | Assessment made by FITD authors, who have a competing method; potential bias in evaluation |\n| As single-turn model alignment improved, attackers shifted toward multi-turn jailbreak strategies | \"As model alignment improved, many one-shot exploits became ineffective, leading to a shift toward multi-turn jailbreaks.\" | [xteaming, xteaming_c16] | HIGH | Reflects a broad trend; no quantitative threshold for \"improved alignment\" is specified |\n| Crescendo uses only human-readable, innocuous prompts and relies on the model's own outputs rather than adversarial text | \"Crescendo does not use any adversarial or malicious text in its prompts. The inputs for Crescendo are completely human-readable and innocuous. This is due to Crescendo's design, which relies on the model's own output rather than crafting explicit content.\" | [crescendo, crescendo_c05] | HIGH | This design makes Crescendo significantly harder to detect than attacks using explicit adversarial content |\n| Existing multi-turn safety datasets are small-scale and lack diversity, failing to capture nuanced multi-turn interaction risks | \"The few available multi-turn safety datasets like SafeMTData are small in scale and generated using frameworks with limited attack diversity, and often overoptimize for specific types of attacks only.\" | [xteaming, xteaming_c16] | HIGH | Identified as a critical gap motivating the X-Teaming/X-Guard-Train contribution |\n| Current safety benchmarks and datasets predominantly focus on single-turn interactions, leaving a significant gap for multi-turn safety evaluation | \"Current safety resources, including datasets, benchmarks, and safety classifiers, predominantly focus on single-turn interactions, leaving a significant gap in high-quality materials tailored specifically for evaluating and training multi-turn conversational safety.\" | [xteaming, xteaming_c16] | HIGH | Gap acknowledged broadly; no quantitative estimate of how large the gap is provided |\n| The FITD method uses SSParaphrase and Re-Align mechanisms to handle target model rejections during multi-turn attacks | \"SSParaphrase refines queries by generating intermediate malicious-level queries between the last and current query. Re-Align uses prompt alignment to align the target model's responses.\" | [fitd, fitd_c05] | HIGH | Algorithmic detail confirmed by pseudocode in [fitd, fitd_c12]; implementation complexity may affect reproducibility |\n| White-box single-turn attacks use gradient-based optimization, while black-box attacks rely on input transformations such as ciphers or low-resource languages | \"Black-box single-turn attacks use input transformations to bypass safety constraints...such as encoding adversarial prompts in ciphers, low-resource languages, or code. In contrast, white-box single-turn attacks exploit access to model parameters using gradient-based optimization.\" | [fitd, fitd_c05] | HIGH | Taxonomy is widely accepted but presented here as background framing by FITD authors |\n| X-Teaming employs TextGrad optimization to enable adaptive, diverse multi-turn attack trajectories, distinguishing it from fixed-seed approaches | \"Unlike self-talk methods, we use TextGrad to optimize prompts based on actual model responses, allowing adaptive search...our multi-agent strategy with TextGrad optimization enables diverse, adaptive trajectories spanning multiple attack strategies.\" | [xteaming, xteaming_c16] | HIGH | Comparative advantage claimed by X-Teaming authors; direct head-to-head ASR comparison not included in provided chunks |",
  "timestamp": "2026-03-01T20:15:30.472536+00:00"
}