{
  "model": "claude-haiku-4-5",
  "system_prompt_hash": "7c1ee11d93629999",
  "user_message_hash": "439a1b3461955018",
  "max_tokens": 2048,
  "response": "## PAIR Attack Method Overview\n\nPAIR (Prompt Automatic Iterative Refinement) is a black-box jailbreaking method that uses an attacker LLM to automatically generate semantic jailbreaks against a target LLM without human intervention [pair, pair_c02].\n\n## How PAIR Works\n\nPAIR operates through a four-step iterative process [pair, pair_c06]:\n\n1. **Attack Generation**: The attacker LLM A receives targeted system prompts that direct it to generate a candidate jailbreak prompt P designed to compromise the target model T.\n\n2. **Target Response**: The candidate prompt P is submitted to the target model T, which produces a response R.\n\n3. **Jailbreak Scoring**: A JUDGE component evaluates both the prompt P and response R, assigning a score S to determine whether a successful jailbreak occurred.\n\n4. **Iterative Refinement**: If the score indicates failure (S = 0), the prompt P, response R, and score S are fed back to the attacker LLM, which then generates an improved candidate prompt. This back-and-forth conversational interaction continues until a jailbreak succeeds [pair, pair_c06].\n\n## Key Advantages\n\nThe method is inspired by social engineering attacks and critically relies on iterative collaboration between the attacker and target LLMs [pair, pair_c02]. PAIR is remarkably efficient, often requiring fewer than twenty queries to produce a jailbreak\u2014orders of magnitude more efficient than existing algorithms [pair, pair_c02]. Additionally, because it only requires black-box query access, PAIR doesn't need GPUs, making it inexpensive and accessible for red teaming purposes [pair, pair_c19].",
  "timestamp": "2026-03-01T19:48:16.652633+00:00"
}