{
  "model": "claude-haiku-4-5",
  "system_prompt_hash": "7c1ee11d93629999",
  "user_message_hash": "6f7f18fa908b6a9c",
  "max_tokens": 2048,
  "response": "# How ArtPrompt Uses ASCII Art to Bypass LLM Safety Filters\n\nArtPrompt exploits two key vulnerabilities in LLM safety mechanisms:\n\n## Core Mechanism\n\n**Recognition Vulnerability:** LLMs struggle to recognize and interpret words when they are represented as ASCII art. By substituting sensitive words that would normally trigger safety rejections with ASCII art representations, ArtPrompt increases the probability of bypassing safety measures. [artprompt, artprompt_c10]\n\n**Contextual Inference:** Although LLMs cannot directly interpret ASCII art representations, they can still infer the meaning of the masked word based on the surrounding context in the prompt. This allows the model to understand the harmful intent while the safety filters fail to detect it. [artprompt, artprompt_c10]\n\n## Implementation Strategy\n\nArtPrompt operates in two steps: [artprompt, artprompt_c10]\n\n1. **Word Masking:** The attacker identifies and masks sensitive words in the prompt that would conflict with LLM safety alignment and cause rejection.\n\n2. **Cloaked Prompt Generation:** An ASCII art generator replaces the identified words with ASCII art representations, which are then substituted back into the original prompt before sending it to the target LLM.\n\n## Effectiveness\n\nThe approach exploits a fundamental weakness in current safety alignment techniques, which presume that training corpora are interpreted solely through semantics. ArtPrompt bypasses this assumption by encoding harmful content in a non-semantic, visual format that LLMs cannot adequately recognize. [artprompt, artprompt_c02], [artprompt, artprompt_c03]",
  "timestamp": "2026-03-01T19:48:49.417065+00:00"
}