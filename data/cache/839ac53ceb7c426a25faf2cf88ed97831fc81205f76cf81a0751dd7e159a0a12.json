{
  "model": "claude-sonnet-4-6",
  "system_prompt_hash": "e86b58f46f5b8953",
  "user_message_hash": "df4caf1719986d68",
  "max_tokens": 4096,
  "response": "# Evidence Table: Multi-Turn Jailbreak Attack Strategies and Their Effectiveness\n\n| Claim | Evidence | Citation | Confidence | Notes |\n|-------|----------|----------|------------|-------|\n| FITD achieves state-of-the-art ASR averaging ~94% across seven LLMs | \"FITD consistently outperforms all baseline attacks across all evaluated models. It achieves 98%/93% on LLaMA-3-8B and maintains an ASR on average 94%/91% across all tested models.\" | [fitd, fitd_c16] | HIGH | Evaluated on JailbreakBench and HarmBench; requires avg. 16 queries per malicious question |\n| Multi-turn attacks outperform single-turn attacks as model alignment improves | \"As model alignment improved, many one-shot exploits became ineffective, leading to a shift toward multi-turn jailbreaks.\" | [xteaming, xteaming_c16] | HIGH | Shift reflects an arms race dynamic; single-turn methods like GCG still require white-box access |\n| Crescendomation outperforms all compared single-turn and multi-turn baselines on GPT-4 and Gemini-Pro | \"Crescendo achieves 56.2% average ASR (98.0% binary) on GPT-4 and 82.6% (100%) on Gemini-Pro, outperforming CIA, CoA, MSJ, and PAIR.\" | [crescendo, crescendo_c26] | HIGH | Comparison predates FITD; FITD later reports higher ASR, suggesting Crescendo has since been surpassed |\n| PAIR achieves jailbreak success in ~10\u201334 queries on most models but fails on Claude-1/2 | \"PAIR achieves 88% on Vicuna, 51% on GPT-3.5, 48% on GPT-4, and 73% on Gemini, but only 3% on Claude-1 and 0% on Claude-2.\" | [pair, pair_c09] | HIGH | PAIR is a black-box iterative refinement method; Claude models appear substantially more robust |\n| Combining multiple single-turn attack techniques dramatically increases ASR | \"combination_3 [composing prefix injection, refusal suppression, Base64, style injection, website generation] achieves a BAD BOT rate of 0.94 on GPT-4 and 0.81 on Claude v1.3.\" | [how_do_llms_fail, how_do_llms_fail_c13] | HIGH | Single techniques individually score much lower; adaptive attack achieves 1.00 on both models |\n| Existing multi-turn attacks are limited by fixed seeds and constrained interaction patterns | \"Existing approaches often rely on fixed seeds (Russinovich et al., 2024) or constrained interaction patterns (Ren et al., 2024)... they rely on narrow strategies with fixed seeds or constrained interaction patterns.\" | [xteaming, xteaming_c16] | HIGH | Cited as motivation for X-Teaming's adaptive multi-agent approach; corroborated by [fitd, fitd_c05] |\n| Current safety datasets are predominantly single-turn and inadequate for multi-turn threat evaluation | \"Current safety resources...predominantly focus on single-turn interactions, leaving a significant gap in high-quality materials tailored specifically for evaluating and training multi-turn conversational safety.\" | [xteaming, xteaming_c16] | HIGH | Identified as a systemic gap; multi-turn datasets like SafeMTData are noted as small-scale and low-diversity |\n| Crescendo uses only benign, human-readable prompts, making it harder to detect than adversarial-text attacks | \"Crescendo does not use any adversarial or malicious text in its prompts... it poses a significantly greater challenge for detection and mitigation compared to other techniques.\" | [crescendo, crescendo_c05] | HIGH | Contrasts with GCG-style attacks that use gibberish suffixes; detection difficulty is asserted but not empirically quantified in provided chunks |\n| FITD exploits a psychological \"foot-in-the-door\" self-corruption phenomenon to progressively erode LLM alignment | \"FITD takes advantage of the psychological dynamics of multi-turn conversation, rooted in the foot-in-the-door effect, to exploit the inherent vulnerabilities in the alignment of LLMs.\" | [fitd, fitd_c04] | HIGH | Mechanism relies on Re-Align and SSParaphrase components; self-corruption phenomenon is analyzed in-depth per authors |\n| LLM prompt rewriting and scenario nesting (ReNeLLM) is the most effective single-turn baseline approach | \"Among single-turn attacks, ReNeLLM achieves the highest ASR on average, significantly outperforming other single-turn baselines. This suggests that leveraging LLMs for prompt rewriting and scenario nesting is a highly effective approach.\" | [fitd, fitd_c16] | HIGH | ReNeLLM averages 75%/61% ASR \u2014 strong but still below FITD's 94%/91%; DeepInception and CodeChameleon both fall below 34% avg. |",
  "timestamp": "2026-03-01T20:49:12.695593+00:00"
}