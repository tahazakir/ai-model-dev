{
  "model": "claude-haiku-4-5",
  "system_prompt_hash": "7c1ee11d93629999",
  "user_message_hash": "e5e48eacf099a92b",
  "max_tokens": 2048,
  "response": "# Agent Smith Attack Propagation Mechanism\n\nThe Agent Smith attack propagates jailbreaks across multiple multimodal LLM agents through a process called **infectious jailbreak** in multi-agent environments.\n\n## Attack Initiation and Spread\n\nThe attack begins with a single adversarial image. According to the research, an adversary \"simply jailbreak[es] a single agent, and without any further intervention from the adversary, (almost) all agents will become infected exponentially fast and exhibit harmful behaviors.\" [agentsmith, agentsmith_c02] Specifically, \"feeding an (infectious) adversarial image into the memory of any randomly chosen agent is sufficient to achieve infectious jailbreak.\" [agentsmith, agentsmith_c02]\n\n## Propagation Mechanism\n\nThe propagation occurs through **agent-to-agent communication**. The research formalizes this through \"randomized pairwise chat as a proof-of-concept instantiation for multi-agent interaction,\" which establishes \"the infectious dynamics of randomized pairwise chat in a multi-agent environment.\" [agentsmith, agentsmith_c06] As agents communicate with each other, the jailbreak spreads from one agent to another in an exponential manner.\n\n## Scale of Impact\n\nThe researchers validated this attack at massive scale: \"we simulate multi-agent environments containing up to one million LLaVA-1.5 agents\" and demonstrated that the infectious jailbreak is feasible across these large-scale deployments. [agentsmith, agentsmith_c02]\n\nThe research notes that while they have derived \"a simple principle for determining whether a defense mechanism can provably restrain the spread of infectious jailbreak,\" designing practical defenses remains an open challenge. [agentsmith, agentsmith_c02]",
  "timestamp": "2026-03-01T19:48:20.429085+00:00"
}