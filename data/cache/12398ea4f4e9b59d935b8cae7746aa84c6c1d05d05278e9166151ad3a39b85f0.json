{
  "model": "claude-sonnet-4-6",
  "system_prompt_hash": "e86b58f46f5b8953",
  "user_message_hash": "a4b504eda7beede2",
  "max_tokens": 4096,
  "response": "# Structured Evidence Table: Multi-Turn Jailbreak Strategies and Their Effectiveness\n\n| Claim | Evidence | Citation | Confidence | Notes |\n|-------|----------|----------|------------|-------|\n| Multi-turn jailbreaks emerged as a response to improved single-turn defenses | \"As model alignment improved, many one-shot exploits became ineffective, leading to a shift toward multi-turn jailbreaks.\" | [xteaming, xteaming_c16] | HIGH | Corroborated by [fitd, fitd_c05] which similarly distinguishes single-turn vs. multi-turn attack evolution |\n| A common multi-turn strategy decomposes harmful queries into innocuous sub-questions to progressively elicit unsafe responses | \"A common approach decomposes harmful queries into a series of innocuous sub-questions, progressively leading the model towards unsafe responses.\" | [fitd, fitd_c05] | HIGH | This tactic is shared across multiple methods (e.g., PANDORA, FITD); effectiveness varies by model |\n| FITD achieves state-of-the-art average attack success rate (ASR) of ~94% across multiple LLMs | \"FITD...achieves an average success rate of 94% on seven widely used models\" and \"maintains an ASR on average 94%/91% across all tested models.\" | [fitd, fitd_c04]; [fitd, fitd_c16] | HIGH | Tested on JailbreakBench and HarmBench; includes both open-source and proprietary models (e.g., GPT-4o, LLaMA) |\n| FITD outperforms all single-turn and multi-turn baseline attacks, including the strongest baseline ActorAttack | \"Our method, FITD, consistently outperforms all baseline attacks across all evaluated models...ActorAttack is the strongest baseline...which achieves 63%/53% on LLaMA-3.1-8B.\" | [fitd, fitd_c16] | HIGH | ActorAttack and CoA are the primary multi-turn baselines; single-turn methods like ReNeLLM peak at ~75% avg. ASR |\n| Crescendo outperforms competing jailbreak techniques (MSJ, PAIR, CIA, CoA) on GPT-4 and Gemini-Pro | \"Crescendo [achieves] 56.2 (98.0) [ASR] on GPT-4 and 82.6 (100.0) on Gemini-Pro,\" compared to PAIR's 40.0/33.0 and MSJ's 37.0/35.4. | [crescendo, crescendo_c26] | HIGH | Comparison limited to 50 AdvBench subset tasks; MSJ implementation was modified due to token limit constraints, potentially affecting fairness |\n| Crescendo uses entirely benign, human-readable prompts, making it harder to detect than adversarial-text-based attacks | \"Crescendo does not use any adversarial or malicious text in its prompts. The inputs for Crescendo are completely human-readable and innocuous...it poses a significantly greater challenge for detection and mitigation.\" | [crescendo, crescendo_c05] | HIGH | Contrasts with gradient-based or cipher-based attacks; detection evasion is claimed but not empirically quantified in provided chunks |\n| Existing multi-turn jailbreak methods are constrained by reliance on fixed, human-crafted seed prompts and limited ASR | \"Crescendo...and ActorAttack...incrementally steer seemingly benign queries toward harmful content but are constrained by their reliance on fixed, human-crafted seed prompts and limited overall ASR.\" | [fitd, fitd_c05] | HIGH | Noted as a limitation by FITD authors; corroborated by X-Teaming authors re: \"fixed seeds or constrained interaction patterns\" [xteaming, xteaming_c16] |\n| Current multi-turn safety datasets are insufficient in scale and diversity, leaving a critical gap in LLM safety evaluation | \"The few available multi-turn safety datasets like SafeMTData are small in scale and generated using frameworks with limited attack diversity, and often overoptimize for specific types of attacks only.\" | [xteaming, xteaming_c16] | HIGH | Existing benchmarks predominantly focus on single-turn interactions; gap identified as motivation for X-Guard-Train dataset |\n| White-box single-turn attacks use gradient-based optimization but require access to model parameters, limiting applicability | \"White-box single-turn attacks exploit access to model parameters using gradient-based optimization to generate adversarial inputs or manipulate text generation configurations.\" | [fitd, fitd_c05] | HIGH | Inapplicable to proprietary/closed-source models; black-box methods like Crescendo and FITD are more broadly deployable |\n| FITD demonstrates cross-model transferability, with adversarial histories from one model successfully bypassing safety mechanisms of others | \"We utilize the progressively malicious query-response history obtained while attacking the source model and directly apply it to other target models...to assess whether adversarial chat histories obtained on one model can successfully bypass the safety mechanisms of others.\" | [fitd, fitd_c16] | MEDIUM | Transferability is tested but specific cross-model ASR results are not fully detailed in the provided chunk; findings are preliminary |",
  "timestamp": "2026-03-01T21:30:46.406460+00:00"
}